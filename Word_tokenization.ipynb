{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFyLC/2JT3Z6KD5LUv4Ujz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anushabhuchupalli/ML-lab/blob/main/Word_tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq-Tvo6SUWaJ",
        "outputId": "ed2deefb-dce7-42fc-b4ac-18e2e195f0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Machine', 'learning', 'is', 'a', 'branch', 'of', 'artificial', 'intelligence', 'and', 'computer', 'science', 'which', 'focuses', 'on', 'the', 'use', 'of', 'data', 'and', 'algorithms', 'to', 'imitate', 'the', 'way', 'that', 'humans', 'learn,', 'gradually', 'improving', 'its', 'accuracy.']\n"
          ]
        }
      ],
      "source": [
        "# Word Tokenization\n",
        "text='''Machine learning is a branch of artificial intelligence and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.'''\n",
        "k=text.split()\n",
        "print(k)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence Tokenization\n",
        "text='''Machine learning is a branch of artificial intelligence and computer science. It focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.Machine learning algorithms use historical data as input to predict new output values.\n",
        "'''\n",
        "sentences=text.split('.')\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUAbXRBilRv4",
        "outputId": "70b7d6e6-039b-4513-c837-f8692af0e89c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Machine learning is a branch of artificial intelligence and computer science', ' It focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy', 'Machine learning algorithms use historical data as input to predict new output values', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n"
      ],
      "metadata": {
        "id": "udfSXOVcl4UL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = re.findall(\"[\\w']+\", text)  \n",
        "print(tokens)\n",
        "print(\"No.of tokens : \", len(tokens))\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcPoRIXol4SC",
        "outputId": "750686a6-aa3c-4fdd-e646-79b074356b0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Machine', 'learning', 'is', 'a', 'branch', 'of', 'artificial', 'intelligence', 'and', 'computer', 'science', 'It', 'focuses', 'on', 'the', 'use', 'of', 'data', 'and', 'algorithms', 'to', 'imitate', 'the', 'way', 'that', 'humans', 'learn', 'gradually', 'improving', 'its', 'accuracy', 'Machine', 'learning', 'algorithms', 'use', 'historical', 'data', 'as', 'input', 'to', 'predict', 'new', 'output', 'values']\n",
            "No.of tokens :  44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence tokenization\n",
        "sentences = re.compile('[.?!] ').split(text)\n",
        "print(sentences)\n",
        "print(\"No.of sentences : \", len(sentences))\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dq_9zwbhnpTf",
        "outputId": "2544a92a-37f5-488b-a280-ad19c06ffe76"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Machine learning is a branch of artificial intelligence and computer science', 'It focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.Machine learning algorithms use historical data as input to predict new output values.\\n']\n",
            "No.of sentences :  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user -U nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzT7XZyzoxx7",
        "outputId": "78676c6b-36ec-4fba-f07b-878438289f7f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ2KwtGBo9vL",
        "outputId": "60243ea1-cb96-4b17-8d4a-87e77fb615ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#word tokenization\n",
        "from nltk.tokenize import word_tokenize \n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)\n",
        "print(\"No.of tokens : \", len(tokens))\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGKYbTJfpRXD",
        "outputId": "7fe812de-ff47-4aa7-ec2c-1a8a4d3d91c7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Machine', 'learning', 'is', 'a', 'branch', 'of', 'artificial', 'intelligence', 'and', 'computer', 'science', '.', 'It', 'focuses', 'on', 'the', 'use', 'of', 'data', 'and', 'algorithms', 'to', 'imitate', 'the', 'way', 'that', 'humans', 'learn', ',', 'gradually', 'improving', 'its', 'accuracy.Machine', 'learning', 'algorithms', 'use', 'historical', 'data', 'as', 'input', 'to', 'predict', 'new', 'output', 'values', '.']\n",
            "No.of tokens :  46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sentence tokenization\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)\n",
        "print(\"No.of sentences : \", len(sentences))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_62Jp_StpUd9",
        "outputId": "a8fc76ec-23f0-4f7e-f082-4788a1b82e77"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Machine learning is a branch of artificial intelligence and computer science.', 'It focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy.Machine learning algorithms use historical data as input to predict new output values.']\n",
            "No.of sentences :  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming words\n",
        "from nltk.stem import PorterStemmer\n"
      ],
      "metadata": {
        "id": "SNpCM10_prUE"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an object of class PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "print(porter.stem(\"processing\"))\n",
        "print(porter.stem(\"troubling\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA_KS2j8pt_S",
        "outputId": "9f4c31bb-9186-4843-8796-7695b31bad1b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "process\n",
            "troubl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "\n",
        "sentence=\"Machine learning is a branch of artificial intelligence and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy..\"\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "def stemSentence(sentence):\n",
        "    token_words=word_tokenize(sentence)\n",
        "    print(token_words)\n",
        "    stem_sentence=[]\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(porter.stem(word))\n",
        "        stem_sentence.append(\" \")\n",
        "    return \"\".join(stem_sentence)\n",
        "\n",
        "x=stemSentence(sentence)\n",
        "print(\"Sentence after stemming :\", x)\n",
        "     \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePmIZYIep3Kn",
        "outputId": "206f5888-d06d-46ea-badc-b8fb7866e795"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Machine', 'learning', 'is', 'a', 'branch', 'of', 'artificial', 'intelligence', 'and', 'computer', 'science', 'which', 'focuses', 'on', 'the', 'use', 'of', 'data', 'and', 'algorithms', 'to', 'imitate', 'the', 'way', 'that', 'humans', 'learn', ',', 'gradually', 'improving', 'its', 'accuracy', '..']\n",
            "Sentence after stemming : machin learn is a branch of artifici intellig and comput scienc which focus on the use of data and algorithm to imit the way that human learn , gradual improv it accuraci .. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rmUMaFhrfPS",
        "outputId": "8a5b36b3-5012-4008-c470-86f3dfb68946"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
        "punctuations=\"?:!.,;\"\n",
        "token_words = nltk.word_tokenize(sentence)\n",
        "print(token_words)\n",
        "\n",
        "lemma_sentence=[]\n",
        "for word in token_words:\n",
        "  lemma_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
        "  lemma_sentence.append(\" \")\n",
        "\n",
        "print(\"lemmas of tokens: \", ''.join(lemma_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2kDU-UZqfkb",
        "outputId": "dc49a634-1911-4a91-bdb7-db5b7253cf94"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['He', 'was', 'running', 'and', 'eating', 'at', 'same', 'time', '.', 'He', 'has', 'bad', 'habit', 'of', 'swimming', 'after', 'playing', 'long', 'hours', 'in', 'the', 'Sun', '.']\n",
            "lemmas of tokens:  He wa running and eating at same time . He ha bad habit of swimming after playing long hour in the Sun . \n"
          ]
        }
      ]
    }
  ]
}